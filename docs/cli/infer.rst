Infer Commands
==============

The ``badc infer`` namespace schedules HawkEars (or a stub runner) across local GPUs/CPUs, writes
per-chunk JSON detections, and aggregates results for downstream analysis.

.. contents:: On this page
   :local:
   :depth: 1

Overview
--------

* Input is always a chunk manifest CSV produced by ``badc chunk``.
* Outputs default to ``artifacts/infer`` (or ``<dataset>/artifacts/infer`` when the manifest lives
  inside a DataLad dataset).
* Telemetry is logged under ``data/telemetry/infer/log.jsonl`` so long runs can be monitored with
  ``badc telemetry``.
* ``--print-datalad-run`` exposes a ready-to-use command for provenance-friendly workflows.

``badc infer run``
------------------

Run HawkEars against every chunk listed in the manifest.

Usage::

   badc infer run MANIFEST.csv [--max-gpus N] [--cpu-workers N]
       [--output-dir PATH] [--runner-cmd CMD | --use-hawkears]
       [--hawkears-arg ARG ...] [--max-retries N]
       [--print-datalad-run]

Key options:

``--max-gpus``
   Limit how many detected GPUs are used. Defaults to "all GPUs reported by ``nvidia-smi``".
``--cpu-workers``
   Worker count when no GPUs exist (or when a CPU-only run is desired). Minimum 1.
``--runner-cmd``
   Custom executable to run per chunk (e.g., a container wrapper). Mutually exclusive with
   ``--use-hawkears``.
``--use-hawkears``
   Invoke the vendored HawkEars ``analyze.py`` script directly. BADC injects chunk/audio arguments
   and parses ``HawkEars_labels.csv`` into JSON detections.
``--hawkears-arg``
   Repeatable passthrough argument (e.g., ``--hawkears-arg --config`` ``--hawkears-arg config.yaml``).
``--max-retries``
   Number of automatic retries per chunk when the runner exits non-zero (default 2).
``--output-dir``
   Override the destination for JSON outputs. When omitted *and* chunks live in a DataLad dataset,
   BADC writes under ``<dataset>/artifacts/infer`` so the files remain inside the dataset boundary.
``--print-datalad-run``
   Instead of running inference, emit a ``datalad run`` command tailored to the manifest/output pair.

Option reference
^^^^^^^^^^^^^^^^

.. list-table::
   :header-rows: 1

   * - Option / Argument
     - Description
     - Default
   * - ``MANIFEST.csv``
     - Chunk manifest generated by ``badc chunk`` commands.
     - Required
   * - ``--max-gpus N``
     - Upper bound on detected GPUs to enlist.
     - All GPUs
   * - ``--cpu-workers N``
     - Worker threads when GPUs are unavailable.
     - ``1``
   * - ``--runner-cmd CMD``
     - Custom executable invoked per chunk.
     - Stub runner
   * - ``--use-hawkears``
     - Call vendored HawkEars ``analyze.py`` instead of a custom runner.
     - Disabled
   * - ``--hawkears-arg ARG``
     - Repeatable passthrough flag forwarded to HawkEars.
     - None
   * - ``--max-retries N``
     - Retry budget for failed chunks.
     - ``2``
   * - ``--output-dir PATH``
     - Destination folder for JSON detections.
     - ``artifacts/infer`` (dataset-aware)
   * - ``--print-datalad-run``
     - Emit provenance-friendly command instead of executing jobs.
     - Disabled

Help excerpt
^^^^^^^^^^^^

.. code-block:: console

   $ badc infer run --help
   Usage: badc infer run [OPTIONS] MANIFEST
     Run HawkEars (or a custom runner) for every chunk in a manifest.
   Arguments:
     MANIFEST  Path to chunk manifest CSV.  [required]
   Options:
     --max-gpus INTEGER       Limit number of GPUs to use.
     --cpu-workers INTEGER    Number of concurrent workers when no GPUs exist.
     --output-dir PATH        Directory for inference outputs.
     --runner-cmd TEXT        Command used to invoke HawkEars (default stub).
     --use-hawkears / --stub-runner  Invoke the embedded HawkEars analyzer.
     --hawkears-arg TEXT      Extra argument to pass to HawkEars (repeatable).
     --max-retries INTEGER    Maximum retries per chunk.
     --print-datalad-run      Show a ready-to-run `datalad run` command.
     --help                   Show this message and exit.

Workflow notes:

* Worker pool: BADC pairs each chunk with a ``GPUWorker`` (index + UUID) derived from ``nvidia-smi``.
  When no GPUs are detected, a CPU thread pool drives the runner.
* Telemetry: every chunk emits a JSON record with timestamps, runtime, status, GPU index, and output
  folder. Monitor progress via ``badc telemetry --log <file>``.
* Failure handling: if any worker raises an exception, the scheduler stops submitting new jobs and
  re-raises the first error after threads finish.

Example::

   badc infer run data/datalad/bogus/manifests/GNWT-290.csv \
       --use-hawkears --max-gpus 2 --hawkears-arg --confidence --hawkears-arg 0.7

``badc infer aggregate``
------------------------

Summarize detection JSON into a CSV that analysts can ingest into notebooks, DuckDB, or dashboards.

Usage::

   badc infer aggregate artifacts/infer --output artifacts/aggregate/summary.csv

Behavior:

* Walks the ``detections_dir`` and parses each JSON file via ``badc.aggregate`` helpers.
* Emits a CSV with one row per detection event (columns include chunk_id, call label, start/end, and
  HawkEars score).
* Skips empty directories with a warning so it is safe to run even before inference completes.

Option reference
^^^^^^^^^^^^^^^^

.. list-table::
   :header-rows: 1

   * - Option / Argument
     - Description
     - Default
   * - ``DETECTIONS_DIR``
     - Folder containing JSON outputs from ``badc infer run``.
     - Required
   * - ``--output PATH``
     - Summary CSV destination.
     - ``artifacts/aggregate/summary.csv``

Help excerpt
^^^^^^^^^^^^

.. code-block:: console

   $ badc infer aggregate --help
   Usage: badc infer aggregate [OPTIONS] DETECTIONS_DIR
     Aggregate per-chunk detection JSON files into a summary CSV.
   Arguments:
     DETECTIONS_DIR  Directory containing inference outputs (JSON).  [required]
   Options:
     --output PATH  Summary CSV path.
     --help         Show this message and exit.

Common pattern::

   badc infer aggregate <dataset>/artifacts/infer --output <dataset>/artifacts/aggregate/summary.csv

Combine with ``datalad run`` or ``git annex`` metadata to track how raw detections feed downstream
reports.
