Infer Commands
==============

The ``badc infer`` namespace schedules HawkEars (or a stub runner) across local GPUs/CPUs, writes
per-chunk JSON detections, and aggregates results for downstream analysis.

.. contents:: On this page
   :local:
   :depth: 1

Overview
--------

* Input is always a chunk manifest CSV produced by ``badc chunk``.
* Outputs default to ``artifacts/infer`` (or ``<dataset>/artifacts/infer`` when the manifest lives
  inside a DataLad dataset).
* Telemetry is logged per run (default ``data/telemetry/infer/<manifest>_<timestamp>.jsonl`` or
  ``<dataset>/artifacts/telemetry/â€¦`` when the manifest lives inside a dataset) and the CLI prints
  the path so ``badc infer monitor`` / ``badc telemetry`` can tail it.
* ``--print-datalad-run`` exposes a ready-to-use command for provenance-friendly workflows.

``badc infer run``
------------------

Run HawkEars against every chunk listed in the manifest.

Usage::

   badc infer run MANIFEST.csv [--max-gpus N] [--cpu-workers N]
       [--output-dir PATH] [--runner-cmd CMD | --use-hawkears]
       [--hawkears-arg ARG ...] [--max-retries N]
       [--print-datalad-run]

Key options:

``--max-gpus``
   Limit how many detected GPUs are used. Defaults to "all GPUs reported by ``nvidia-smi``".
``--cpu-workers``
   Worker count when no GPUs exist (or when a CPU-only run is desired). Minimum 1.
``--runner-cmd``
   Custom executable to run per chunk (e.g., a container wrapper). Mutually exclusive with
   ``--use-hawkears``.
``--use-hawkears``
   Invoke the vendored HawkEars ``analyze.py`` script directly. BADC injects chunk/audio arguments
   and parses ``HawkEars_labels.csv`` into JSON detections.
``--hawkears-arg``
   Repeatable passthrough argument (e.g., ``--hawkears-arg --config`` ``--hawkears-arg config.yaml``).
``--max-retries``
   Number of automatic retries per chunk when the runner exits non-zero (default 2).
``--output-dir``
   Override the destination for JSON outputs. When omitted *and* chunks live in a DataLad dataset,
   BADC writes under ``<dataset>/artifacts/infer`` so the files remain inside the dataset boundary.
``--telemetry-log``
   Override the telemetry log path (JSONL) that records scheduler events. Defaults to a unique file
   per manifest/timestamp under ``data/telemetry/infer`` or ``<dataset>/artifacts/telemetry``.
``--telemetry-log``
   Override the telemetry log path (JSONL) that records scheduler events. Defaults to a unique file
   per manifest/timestamp under ``data/telemetry/infer`` or ``<dataset>/artifacts/telemetry``.
``--print-datalad-run``
   Instead of running inference, emit a ``datalad run`` command tailored to the manifest/output pair.

Option reference
^^^^^^^^^^^^^^^^

.. list-table::
   :header-rows: 1

   * - Option / Argument
     - Description
     - Default
   * - ``MANIFEST.csv``
     - Chunk manifest generated by ``badc chunk`` commands.
     - Required
   * - ``--max-gpus N``
     - Upper bound on detected GPUs to enlist.
     - All GPUs
   * - ``--cpu-workers N``
     - Worker threads when GPUs are unavailable.
     - ``1``
   * - ``--runner-cmd CMD``
     - Custom executable invoked per chunk.
     - Stub runner
   * - ``--use-hawkears``
     - Call vendored HawkEars ``analyze.py`` instead of a custom runner.
     - Disabled
   * - ``--hawkears-arg ARG``
     - Repeatable passthrough flag forwarded to HawkEars.
     - None
   * - ``--max-retries N``
     - Retry budget for failed chunks.
     - ``2``
   * - ``--output-dir PATH``
     - Destination folder for JSON detections.
     - ``artifacts/infer`` (dataset-aware)
   * - ``--telemetry-log PATH``
     - Telemetry log file capturing scheduler events.
     - Derived from manifest name
   * - ``--print-datalad-run``
     - Emit provenance-friendly command instead of executing jobs.
     - Disabled

Help excerpt
^^^^^^^^^^^^

.. code-block:: console

   $ badc infer run --help
   Usage: badc infer run [OPTIONS] MANIFEST
     Run HawkEars (or a custom runner) for every chunk in a manifest.
   Arguments:
     MANIFEST  Path to chunk manifest CSV.  [required]
   Options:
     --max-gpus INTEGER       Limit number of GPUs to use.
     --cpu-workers INTEGER    Number of concurrent workers when no GPUs exist.
     --output-dir PATH        Directory for inference outputs.
     --runner-cmd TEXT        Command used to invoke HawkEars (default stub).
     --use-hawkears / --stub-runner  Invoke the embedded HawkEars analyzer.
     --hawkears-arg TEXT      Extra argument to pass to HawkEars (repeatable).
     --max-retries INTEGER    Maximum retries per chunk.
     --telemetry-log PATH     Telemetry log path (JSONL).
     --print-datalad-run      Show a ready-to-run `datalad run` command.
     --help                   Show this message and exit.

Workflow notes:

* Worker pool: BADC pairs each chunk with a ``GPUWorker`` (index + UUID) derived from ``nvidia-smi``.
  When no GPUs are detected, a CPU thread pool drives the runner.
* Telemetry: every chunk emits a JSON record with timestamps, runtime, GPU index/name, and (when
  available) GPU utilization/memory snapshots. The CLI prints the log path; monitor progress via
  ``badc infer monitor --log <file>`` (rich GPU summary) or ``badc telemetry --log <file>`` (plain
  tail).
* Failure handling: if any worker raises an exception, the scheduler stops submitting new jobs and
  re-raises the first error after threads finish.

Example::

   badc infer run data/datalad/bogus/manifests/GNWT-290.csv \
       --use-hawkears --max-gpus 2 --hawkears-arg --confidence --hawkears-arg 0.7

See :ref:`usage-infer-examples` for more end-to-end command snippets (stub, GPU, and datalad-run).

``badc infer aggregate``
------------------------

Summarize detection JSON into a CSV that analysts can ingest into notebooks, DuckDB, or dashboards.

Usage::

   badc infer aggregate artifacts/infer --output artifacts/aggregate/summary.csv \
       --parquet artifacts/aggregate/detections.parquet

Behavior:

* Walks the ``detections_dir`` and parses each JSON file via ``badc.aggregate`` helpers.
* When ``--manifest`` is supplied, missing chunk metadata (start/end offsets, hashes, recording IDs)
  is filled from the manifest so custom runners that omit chunk metadata still aggregate cleanly.
* Emits a CSV with canonical detection columns (chunk start/end offsets, detection start/end
  relative to the chunk, absolute timestamps, label code/name, confidence, runner + model metadata).
* Optionally writes a Parquet file (requires the ``duckdb`` package) suitable for DuckDB queries or
  downstream analytics notebooks.
* Skips empty directories with a warning so it is safe to run even before inference completes.

Option reference
^^^^^^^^^^^^^^^^

.. list-table::
   :header-rows: 1

   * - Option / Argument
     - Description
     - Default
   * - ``DETECTIONS_DIR``
     - Folder containing JSON outputs from ``badc infer run``.
     - Required
   * - ``--output PATH``
     - Summary CSV destination.
     - ``artifacts/aggregate/summary.csv``
   * - ``--manifest PATH``
     - Optional chunk manifest CSV for metadata enrichment.
     - Disabled
   * - ``--parquet PATH``
     - Optional Parquet export (requires ``duckdb``).
     - Disabled

Help excerpt
^^^^^^^^^^^^

.. code-block:: console

   $ badc infer aggregate --help
   Usage: badc infer aggregate [OPTIONS] DETECTIONS_DIR
     Aggregate per-chunk detection JSON files into canonical summaries.
   Arguments:
     DETECTIONS_DIR  Directory containing inference outputs (JSON).  [required]
   Options:
     --output PATH   Summary CSV path.
     --parquet PATH  Optional Parquet export (requires duckdb).
     --help          Show this message and exit.

Common pattern::

   badc infer aggregate <dataset>/artifacts/infer --output <dataset>/artifacts/aggregate/summary.csv

Combine with ``--manifest`` so chunk metadata survives even when custom runners omit per-chunk JSON
fields. Each detection row now includes chunk-relative start/end times, absolute timestamps, label
codes/names, confidence, runner, and ``model_version`` whenever ``--use-hawkears`` is active. Pair
the command with ``datalad run`` or ``git annex`` metadata to track how raw detections feed downstream
reports. When ``--parquet`` is enabled you can open the file directly in DuckDB::

   duckdb -c "SELECT label, count(*) FROM 'artifacts/aggregate/detections.parquet' GROUP BY 1"

Hand the Parquet export to :doc:`/cli/report` for richer console summaries (group-by label,
recording, or both) or to the :doc:`/howto/aggregate-results` workflow for notebook analysis.

``badc infer monitor``
----------------------

Stream GPU utilization and per-chunk telemetry directly from the JSONL logs produced by
``badc infer run``. The view renders two ``rich`` tables: a per-GPU summary with success/failure
counts, average runtimes, utilization trends (min/avg/max), peak VRAM usage, and ASCII sparklines
showing rolling utilization/VRAM history, plus a live tail of recent chunk events (status, runtime,
GPU, utilization/memory snapshot).

Usage::

   badc infer monitor --log data/telemetry/infer/GNWT-290_20251207T080000Z.jsonl --tail 20

Options:

``--log``
   Telemetry log path. Defaults to ``data/telemetry/infer/log.jsonl`` but the run command prints the
   exact location for each manifest/timestamp.
``--tail``
   Number of recent events to display in the lower table.
``--follow``
   Refresh the tables every ``--interval`` seconds (Ctrl+C to stop).

Use this view during long HawkEars jobs to confirm GPUs remain busy (sustained utilization, stable
VRAM headroom) and to spot failing chunks immediately via the event tail. The sparkline columns
update every refresh when ``--follow`` is enabled, exposing rolling trends without leaving the CLI.
